{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees (CART)  \n",
    "\n",
    "* Sequence of if-else questions about individual features\n",
    "* **Objective**: infer class labels\n",
    "* Able to capture non-linear relationships between features and labels\n",
    "* Don't require feature scaling (ex: Standardization)\n",
    "\n",
    "\n",
    "* **Decision-Tree**: data structure consisting of a hierarcy of nodes\n",
    "* **Decision-Tree for classification**: Used when features are categorical data\n",
    "* **Decision-Tree for regression**: Used when features are continous\n",
    "* **Node**: question or prediction\n",
    "    * **Root node**: first node in tree, *no* parent node, question giving rise to *two* children nodes\n",
    "    * **Internal node**: *one* parent node, question giving rise to *two* children nodes\n",
    "    * **Leaf**: *one* parent node, *no* children nodes --> *prediction*\n",
    "\n",
    "\n",
    "![CART](./img/cart.png \"CART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Regions\n",
    "**Decision region**: region in the feature space where all instances are assigned to one class label.  \n",
    "**Decision boundary**: surface separating different decision regions \n",
    "\n",
    "![linear decision region](./img/decision_region.png \"Linear Decision Region\")\n",
    "\n",
    "**Decision Regions: Linear Model vs. CART\n",
    "\n",
    "![Comparison of decision regions](./img/decision_regions.png \"Comparison of decision regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain (IG)\n",
    "\n",
    "A decision tree is constructed to produce the most pure leaves possible. Each node asks a question about one feature *f* and a split point *sp*.\n",
    "\n",
    "* features and split points are selected by maximizing information gain\n",
    "* Measurement of information gain can be specified (eg: gini-index, entropy)  \n",
    "\n",
    "![Information gain](./img/information_gain.png \"Information Gain\")\n",
    "\n",
    "![Information gain equation](./img/ig_equation.png \"Information gain equation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision-Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "# Generate features\n",
    "X.head() \n",
    "radius_mean  concave points_mean\n",
    "0         17.990             0.147100\n",
    "1         20.570             0.070170\n",
    "2         19.690             0.127900\n",
    "...\n",
    "\n",
    "# View labels\n",
    "y.head()\n",
    "0    1\n",
    "1    1\n",
    "2    1\n",
    "3    1\n",
    "4    1\n",
    "Name: diagnosis, dtype: int64\n",
    "\n",
    "# Split dataset into 80% train 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=1)\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Evaluate test-set accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision-Tree for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "In [2]:\n",
    "print(X.head())\n",
    "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
    "0        17.99         10.38          122.80     1001.0          0.11840   \n",
    "1        20.57         17.77          132.90     1326.0          0.08474   \n",
    "2        19.69         21.25          130.00     1203.0          0.10960   \n",
    "3        11.42         20.38           77.58      386.1          0.14250   \n",
    "4        20.29         14.34          135.10     1297.0          0.10030   \n",
    "\n",
    "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
    "0           0.27760          0.3001              0.14710         0.2419   \n",
    "1           0.07864          0.0869              0.07017         0.1812   \n",
    "2           0.15990          0.1974              0.12790         0.2069   \n",
    "3           0.28390          0.2414              0.10520         0.2597   \n",
    "4           0.13280          0.1980              0.10430         0.1809   \n",
    "\n",
    "   fractal_dimension_mean           ...             radius_worst  \\\n",
    "0                 0.07871           ...                    25.38   \n",
    "1                 0.05667           ...                    24.99   \n",
    "2                 0.05999           ...                    23.57   \n",
    "3                 0.09744           ...                    14.91   \n",
    "4                 0.05883           ...                    22.54   \n",
    "\n",
    "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
    "0          17.33           184.60      2019.0            0.1622   \n",
    "1          23.41           158.80      1956.0            0.1238   \n",
    "2          25.53           152.50      1709.0            0.1444   \n",
    "3          26.50            98.87       567.7            0.2098   \n",
    "4          16.67           152.20      1575.0            0.1374   \n",
    "\n",
    "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
    "0             0.6656           0.7119                0.2654          0.4601  \n",
    "1             0.1866           0.2416                0.1860          0.2750  \n",
    "2             0.4245           0.4504                0.2430          0.3613  \n",
    "3             0.8663           0.6869                0.2575          0.6638  \n",
    "4             0.2050           0.4000                0.1625          0.2364  \n",
    "\n",
    "   fractal_dimension_worst  \n",
    "0                  0.11890  \n",
    "1                  0.08902  \n",
    "2                  0.08758  \n",
    "3                  0.17300  \n",
    "4                  0.07678  \n",
    "\n",
    "In [3]:\n",
    "print(y.head())\n",
    "0    1\n",
    "1    1\n",
    "2    1\n",
    "3    1\n",
    "4    1\n",
    "Name: diagnosis, dtype: int64\n",
    "\n",
    "# Split dataset into 80% train 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2 random_state=3)\n",
    "# Instantiate a DecisionTree Regressor 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.1, random_state=3)\n",
    "# Fit 'dt' to the training-set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict test-set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "# Compute test-set MSE\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "# Compute test_set RMSE\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "# Print rmse_dt\n",
    "print(rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Instantiate a linear regressor 'lr'\n",
    "lr = LinearRegression()\n",
    "# Fit 'lr' to the training-set\n",
    "lr.fit(X_train, y_train)\n",
    "# Predict test set labels \n",
    "y_pred_lr = lr.predict(X_test)\n",
    "# Compute mse_lr\n",
    "mse_lr = MSE(y_pred_lr, y_test)\n",
    "# Compute rmse_lr\n",
    "rmse_lr = mse_lr**(1/2)\n",
    "\n",
    "# Print rmse_lr\n",
    "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
    "\n",
    "# Print rmse_dt\n",
    "print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias & Variance\n",
    "\n",
    "## Goals of supervised learning\n",
    "\n",
    "* Given $y = f(x)$ and $f$ is unknown\n",
    "* Find a model $\\hat f$ that best approximates $f$: $\\hat f \\approx f$\n",
    "* $\\hat f$ can be any model (eg: Logistic regression, decision-tree, neural network)\n",
    "* Discard as much noise as possible\n",
    "* $\\hat f$ should achieve a low predictive error on unseen data\n",
    "\n",
    "![function](./img/f.png \"funtion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges Approximating $f$\n",
    "\n",
    "**Overfitting**: $\\hat f (x)$ fits the training set noise  \n",
    "* model has low training set error\n",
    "* model has high test set error\n",
    "\n",
    "![Overfitting](./img/overfit.png \"Overfitting\")\n",
    "\n",
    "**Underfitting**: $\\hat f$ is not flexible enough to approximate $f$  \n",
    "* model training set error is close to test set error, but both are high\n",
    "\n",
    "![Underfitting](./img/underfit.png \"Underfitting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization Error\n",
    "**Generalization Error of $\\hat f$**: quantifies how well $\\hat f$ generalizes to unseen data\n",
    "\n",
    "$\\hat f = bias^2 + variance + irreducible\\ error$  \n",
    "* **bias**: quantifies how much $\\hat f \\ne f$\n",
    "* **variance**: quantifies how much $\\hat f$ is inconsistent over differnt training sets\n",
    "* **irreducible error**: noise\n",
    "\n",
    "### Bias\n",
    "High bias leads to underfitting\n",
    "\n",
    "![bias](./img/bias.png \"bias\")\n",
    "\n",
    "### Variance\n",
    "High variance leads to overfitting\n",
    "\n",
    "![variance](./img/variance.png \"variance\")\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "**model complexity**: sets the flexibility of $\\hat f$ (eg: maximum tree depth, minimum samples per leaf, number of samples)\n",
    "\n",
    "![bias-variance](./img/bias_variance.png \"Bias-Variance Tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation with K-Fold CV  \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "* Split the training set randomly into 10 folds  \n",
    "* Train on K-1 folds and estimate error on the Kth fold  \n",
    "* Repeat until each fold has been used to estimate error \n",
    "* Compute CV-error as the mean of the K error estimates  \n",
    "\n",
    "$CV error = \\frac{E_{1} + ... + E_{10}}{10}$\n",
    "\n",
    "![k-fold cv](./img/k_fold_cv.png \"k-fold cv\")\n",
    "\n",
    "### Diagnosing bias and variance problems  \n",
    "#### High variance\n",
    "* CV-error > $\\hat{f}\\ training\\ error$\n",
    "* Model overfits the training data  \n",
    "* Decrease model complexity  \n",
    "    * reduce maximum-tree-depth  \n",
    "    * increase maximum-samples-per-leaf  \n",
    "    * gather more training samples  \n",
    "#### High Bias\n",
    "* CV-error $\\approx$ $\\hat{f}\\ training\\ error$ AND > desired error  \n",
    "* Model underfits the training data  \n",
    "* Increase model complexity  \n",
    "    * increase maximum-tree-depth  \n",
    "    * decrease maximum-samples-per-leaf  \n",
    "    * gather more relevant features  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Generalization Error\n",
    "Generalization error cannot be directly estimated becuase:\n",
    "* the true function $f$ is unknown\n",
    "* There is only one dataset\n",
    "* Noise is unpredictable\n",
    "\n",
    "Splitting the data into training and test sets allows for assesment of GE.\n",
    "* split the data into training and test sets\n",
    "* fit $\\hat f$ to the training set\n",
    "* evaluate the error of $\\hat f$ on the **unseen** test set\n",
    "* generalization error of $\\hat f \\approx$ test set error of $\\hat f$\n",
    "* But, this procedure often produces an optimistic estimate of GE, because the model has already been exposed to the training set when fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Set seed for reproducibility\n",
    "SEED = 123\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=SEED)\n",
    "# Instantiate decision tree regressor as 'dt'\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.14, random_state=SEED)\n",
    "\n",
    "# Evaluate the list of MSE obtained by 10-fold CV\n",
    "# Set n_jobs to -1 in order to exploit all CPU cores\n",
    "# Multiply by -1 to convert array of negative MSE to MSE\n",
    "MSE_CV = - cross_val_score(dt, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# Fit 'dt' to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the labels of the training set\n",
    "y_predict_train = dt.predict(X_train)\n",
    "# Predict the labels of the test set\n",
    "y_predict_test = dt.predict(X_test)\n",
    "\n",
    "# Diagnose bias and variance problems\n",
    "# CV MSE\n",
    "print('CV MSE: {:.2f}'.format(MSE_CV.mean()))\n",
    "# Traiing set MSE\n",
    "print('Train MSE: {:.2f}'.format(MSE(y_train, y_predict_train)))\n",
    "# Test set MSE\n",
    "print('Test MSE: {:.2f}'.format(MSE(y_test, y_predict_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "**Limitations of CARTs**  \n",
    "* Classificataion: can only produce orthagonal decision boundaries\n",
    "* Sensitive to small variations in the training set\n",
    "* High variance: unconstrained CARTs may overfit the training set \n",
    "\n",
    "**Ensemble Learning**\n",
    "* Train different models on the same dataset\n",
    "* Let each model make its predictions\n",
    "* **Meta-model**: aggregates predictions of individual models \n",
    "* Final prediction is more robust\n",
    "* Ideally, individual models are skillful in differnt ways\n",
    "\n",
    "![ensemble learning](./img/ensemble.png \"Ensemble Learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting classifier\n",
    "Combination of multiple models produced by differnt algorithms into a meta-model. Case predictions are resolved with majority voting.\n",
    "\n",
    "* Binary classification task \n",
    "* $N$ classifiers make predictions: $P_{1}, P_{2},...P_{N}$ with $P_{i}=0 or 1$\n",
    "* Meta-model prediction uses hard voting\n",
    "\n",
    "![voting classifier](./img/voting.png \"Voting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "# Splint data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate individual classifiers\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "knn = KNN()\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "# Define a list of (classifier_name, classifier) tuples\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n",
    "# Iterate over the classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    # fit clf to the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))\n",
    "\n",
    "# Instantiate voting classifier\n",
    "vc = VotingClassifier(estimators=classifiers)\n",
    "# Fit 'vc' to the training set and predict test set labels\n",
    "vc.fit(X_train, y_train)\n",
    "y_pred = vc.predict(X_test)\n",
    "# Evaluate the test-set accuracy of 'vc'\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap aggregation - Bagging\n",
    "Combination of multiple models using the same algorithm, each trained on a random subset of the trainng set. \n",
    "* Classification models aggregate predictions by majority voting. \n",
    "* Regression models aggregate predictions through averaging. \n",
    "* Reduces variance of individual models in the ensemble.\n",
    "\n",
    "![bagging](./img/bagging.png \"Bagging\")\n",
    "\n",
    "![predictions](./img/predictions.png \"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "\n",
    "# Instantiate a classification-tree\n",
    "df = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=SEED)\n",
    "# Instantiate a BaggingClassifier\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, n_jobs=-1)\n",
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate and print test-set accuracy\n",
    "acuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of Bagging Classifier: {:.3f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Bag (OOB) evaluation\n",
    "Random sampling of the training set only selects 63% of the data on average. The remaining 37% are OOB instances. \n",
    "* OOB instances can be used as a test set\n",
    "* By combining these results, Cross-Validation can be eliminated\n",
    "* Sklearn uses `accuracy_score` for classifiers and $r^2$ for regresors.\n",
    "\n",
    "![OOB](./img/oob.png \"OOB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "\n",
    "# Instantiate a classification-tree\n",
    "df = DecisionTreeClassifier(max_depth=4, min_samples_leaf=0.16, random_state=SEED)\n",
    "# Instantiate a BaggingClassifier with oob_score\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, oob_score=True, n_jobs=-1)\n",
    "# Fit 'bc' to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "# Extract the OOB accuracy from 'bc'\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "# Print test set accuracy\n",
    "print('Test set accuracy: {:.3f}'.format(test_accuracy))\n",
    "# Print OOB accuracy\n",
    "print('OOB accuracy: {:.3f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Ensemble method for Decision Tree models. \n",
    "* Base estimator: Decision tree\n",
    "* Multiple estimators are trained on different bootstrap samples with the same size as the training set.\n",
    "* Individual trees are further randomized by sampling $d < total features$ at each node without replacement.\n",
    "\n",
    "![random forrest](./img/random_forest.png \"Random Forest\")\n",
    "\n",
    "* Classification models aggregate predictions by majority voting. \n",
    "* Regression models aggregate predictions through averaging.\n",
    "\n",
    "![predictions](./img/rf_predictions.png \"Random Forest Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as MSE\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a random forests regressor 'rf'\n",
    "rf = RandomForestRegressor(n_estimators=400, min_samples_leaf=.12, random_state=SEED)\n",
    "# Fit 'rf to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "# Predict the test set labels 'y_pred'\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "#Print the test set RMSE\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "Tree-based methods allow for evaluation of the importance of each feature in prediction. Sklearn records each nodes' reduction of impurity as a weighted average in the attribute `feature_importance_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandasimport matplotlib.pyplot as plt \n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances_rf = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "\n",
    "# Make a horizontal bar plot\n",
    "sorted_importances_rf.plot(kind='barh', color='lightgreen'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Ensemble method combining several weak learners (slightly better than random guessing) to create a strong learner. Predictors are trained sequentially and subsequent predictors try to correct the predecessor. EG: AdaBoost, Gradient Boosting  \n",
    "\n",
    "## Adaptive Boosting (Adaboost)\n",
    "\n",
    "* Each predictor pays more attention to instances incorrectly predicted by its predecessor.\n",
    "* Accomplished by changing weights of training instances\n",
    "* Once predictors are trained, labels of new instances are assigned by *weighted* majority voting in classification problems and *weighted* average in regression problems\n",
    "\n",
    "### Training error\n",
    "* Each predictor is assigned a coefficient $\\alpha$\n",
    "* $\\alpha$ depends on the predictor's training error\n",
    "\n",
    "![AdaBoost](./img/adaboost.png \"AdaBoost\")\n",
    "\n",
    "### Learning rate\n",
    "* $\\eta$ is a number between 0 & 1 that reduces the $\\alpha$ of the trained predictors\n",
    "* There is an inverse relationship between $\\eta$ and the number of predictors. Smaller values of $\\eta$ need to be offset with more estimators.\n",
    "\n",
    "![learning rate](./img/learning.png \"Learning Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, stratify=y, random_state=SEED)\n",
    "\n",
    "# Instantiate a classification-tree (max_depth=1 is a decision stump)\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state=SEED)\n",
    "# Instantiate an AdaBoost classifier\n",
    "adab_clf = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "\n",
    "# Fit AdaBoost classifier to training set\n",
    "adab_clf.fit(X_train, y_train)\n",
    "# Predict the test set probabilites of positive class\n",
    "y_pred_proba = adb_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "adb_clf_roc_auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print('ROC AUC score: {:.2f}'.format(adb_clf_roc_auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting\n",
    "\n",
    "* A CART is used as a base learner\n",
    "* Predictors are trained using predecessor's residual errors as labels\n",
    "\n",
    "![Gradient Boosting](./img/gb.png \"Gradient Boosting\")\n",
    "\n",
    "### Shrinkage\n",
    "* Each tree's prediction shrinks when multiplied by $\\eta$\n",
    "* As learning rate is reduced, the number of predictors needs to increase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a `GradientBoostingRegressor`\n",
    "gbt = GradientBoostingRegressor(n_estimators=300, max_depth=1, random_state=SEED)\n",
    "\n",
    "#Fit to training set\n",
    "gbt.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "y_pred = gbt.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting (SGB)  \n",
    "\n",
    "Gradient Boosting can have duplications in predictors. CARTs are trained to find the best split points and features which can result in multiple CARTs using the same split points and features.  \n",
    "\n",
    "SGB creates ensemble diversity\n",
    "* Each tree is trained on a random subset of instances in the training data\n",
    "* The sampled instances (40%-80% of the training set) are sampled without replacement\n",
    "* Features are sampled (without replacement) when choosing split points\n",
    "\n",
    "![Stochastic Gradient Boosting](./img/sgb.png \"Stochastic Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "SEED = 1\n",
    "# Split data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a `GradientBoostingRegressor`\n",
    "sgbt = GradientBoostingRegressor(max_depth=1,subsample=0.8, max_features=0.2, n_estimators=300, random_state=SEED)\n",
    "\n",
    "#Fit to training set\n",
    "sgbt.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "y_pred = sgbt.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n",
    "\n",
    "* **Parameters**: learned from data \n",
    "    * CART example: split-point of a node, split-feature of a node, etc.\n",
    "* **Hyperparameters**: not learned from data; set in model specification\n",
    "    * CART example: `max_depth`, `min_samples_leaf`, splitting criterion, etc\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "* The search for a set of optimal hyperparameters for a learning algorithm\n",
    "* Tuning is computationally expensive\n",
    "* May lead to only slight improvements\n",
    "* **Score**: quantifies model optimization\n",
    "    * classification uses accuracy\n",
    "    * regressio uses $R^2$\n",
    "* Cross validation is used to estimate the generalization performace\n",
    "* Many approaches to Hyperparameter tuning\n",
    "    * Grid search\n",
    "    * Random search\n",
    "    * Bayesian optimization\n",
    "    * Genetic algorithms\n",
    "    * ...\n",
    "\n",
    "### Grid Search Cross validation\n",
    "* Manually set a grid of discrete hyperparameter values\n",
    "* set a metric for scoring model performace\n",
    "* Search exhastively through the grid\n",
    "* For each set of hyperparameters, evaluate each model's CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "# Print hyperparameters\n",
    "print(dt.get_params())\n",
    "\n",
    "# Define the grid of hyperparameters to optimize\n",
    "params_dt = {\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'min_samples_leaf': [0.04, 0.06, 0.08],\n",
    "    'max_features': [0.2, 0.4, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "# Instantiate a 10-fold CV grid search object\n",
    "grid_dt = GridSearchCV(estimator=dt, param_grid=params_dt, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "# Fit to the training data\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# Extract best hyperparameters\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)\n",
    "\n",
    "# Extract best CV score\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy'.format(best_CV_score))\n",
    "\n",
    "# Extract best model\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "#Evaluate test set accuracy\n",
    "test_acc = best_model.score(X_test, y_test)\n",
    "print(\"Test set accuracy of best model: {:.3f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSPH-Healthcare-PACE",
   "language": "python",
   "name": "gsph-healthcare-pace"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
